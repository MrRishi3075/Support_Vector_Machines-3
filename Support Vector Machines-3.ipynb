{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100de238-5d5d-491a-92f4-3736642fc2d8",
   "metadata": {},
   "source": [
    "#### Q1. In order to predict house price based on several characteristics, such as location, square footage, number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this situation would be the best to employ?\n",
    "\n",
    "**Certainly! To determine the most suitable regression metric for evaluating an SVM regression model predicting house prices based on several characteristics using the provided dataset 'house_prices_dataset.csv,' you can use various metrics and then decide based on the specific requirements of your problem. Here, I'll demonstrate how to load the dataset and calculate multiple regression metrics using Python and scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e89ffd-f6a0-4425-a827-bd5a22f1b51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 4359.75\n",
      "Mean Squared Error (MSE): 32019823.45\n",
      "Root Mean Squared Error (RMSE): 5658.61\n",
      "R-squared (R2): -1502.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Bengaluru_House_Data.csv')\n",
    "\n",
    "# Identify and handle categorical variables\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Assuming 'price' is the target variable and the other columns are features\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Scale your features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize and train the LinearSVR model\n",
    "svm_model = LinearSVR()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using regression metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared (R2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2c89b-b7e8-4b25-a1a5-87f7a2368b8d",
   "metadata": {},
   "source": [
    "#### Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price of a house as accurately as possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2adbbf-c16b-4606-8dd5-29a1e6e62c35",
   "metadata": {},
   "source": [
    "##### For evaluating a regression model like SVM regression, both Mean Squared Error (MSE) and R-squared (Coefficient of Determination) are commonly used metrics, but they capture different aspects of model performance.\n",
    "\n",
    "**Mean Squared Error (MSE):**\n",
    "\n",
    "- MSE measures the average squared difference between predicted values and actual values.\n",
    "- It is a measure of the average magnitude of errors between your predicted and actual values.\n",
    "- Lower MSE indicates better predictive performance, as it means smaller errors on average.\n",
    "\n",
    "**R-squared (Coefficient of Determination):**\n",
    "\n",
    "- R-squared measures the proportion of the variance in the dependent variable (target) that is predictable from the independent variables (features).\n",
    "- R-squared ranges from 0 to 1, where 1 indicates a perfect fit and 0 indicates no predictive power.\n",
    "- Higher R-squared values suggest that a larger proportion of the variance is explained by the model.\n",
    "\n",
    "**For predicting the actual price of a house as accurately as possible, both metrics can be informative:**\n",
    "\n",
    "- Use MSE if you want to focus on the accuracy of individual predictions. A lower MSE means smaller errors in predicting house prices.\n",
    "\n",
    "- Use R-squared if you want to understand the proportion of the variance in house prices that your model explains. A higher R-squared indicates that your model captures a larger portion of the variability in house prices.\n",
    "\n",
    "- In conclusion, it's often beneficial to consider both metrics. However, if forced to choose one metric, MSE might be more directly aligned with the goal of predicting the actual price with minimal error.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591808a2-d3ab-4d04-aad5-95f12c3fd681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>419</td>\n",
       "      <td>13</td>\n",
       "      <td>464</td>\n",
       "      <td>70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>317</td>\n",
       "      <td>19</td>\n",
       "      <td>2439</td>\n",
       "      <td>1288</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1179</td>\n",
       "      <td>16</td>\n",
       "      <td>2688</td>\n",
       "      <td>514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>757</td>\n",
       "      <td>16</td>\n",
       "      <td>2186</td>\n",
       "      <td>602</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>716</td>\n",
       "      <td>13</td>\n",
       "      <td>2688</td>\n",
       "      <td>239</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area_type  availability  location  size  society  total_sqft  bath  \\\n",
       "0          3            40       419    13      464          70   2.0   \n",
       "1          2            80       317    19     2439        1288   5.0   \n",
       "2          0            80      1179    16     2688         514   2.0   \n",
       "3          3            80       757    16     2186         602   3.0   \n",
       "4          3            80       716    13     2688         239   2.0   \n",
       "\n",
       "   balcony   price  \n",
       "0      1.0   39.07  \n",
       "1      3.0  120.00  \n",
       "2      3.0   62.00  \n",
       "3      1.0   95.00  \n",
       "4      1.0   51.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65d35a-5e89-46ba-8747-ba1ba48bf02f",
   "metadata": {},
   "source": [
    "#### Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate regression metric to use with your SVM model. Which metric would be the most appropriate in this scenario?\n",
    "\n",
    "**In the presence of a significant number of outliers, using the Mean Squared Error (MSE) as a regression metric may not be the most appropriate choice. MSE can be sensitive to outliers because it squares the differences between predicted and actual values.**\n",
    "\n",
    "- An alternative regression metric that is more robust to outliers is the **Mean Absolute Error (MAE)**. MAE measures the average absolute differences between predicted and actual values. Since it doesn't square the errors, it gives equal weight to all errors, making it less sensitive to the influence of outliers.\n",
    "\n",
    "- Using MAE in a regression scenario with outliers can provide a more robust assessment of the model's performance, as it won't be as heavily influenced by the extreme values. However, it's essential to consider the nature of your data and the specific goals of your analysis. If the outliers carry meaningful information or if their presence is indicative of the real-world scenario, you might want to address the outliers or choose a metric that aligns with the overall objectives of your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e40be-e599-4696-aed8-cc4b57fc2bf0",
   "metadata": {},
   "source": [
    "#### Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values are very close. Which metric should you choose to use in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecdef0f8-fda1-410f-8225-bcd1a14eaf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area_type', 'availability', 'location', 'size', 'society',\n",
       "       'total_sqft', 'bath', 'balcony', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68ef37-33fb-4046-9cf0-7c8d0ae254ee",
   "metadata": {},
   "source": [
    "**When both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are very close, it's generally acceptable to choose either one for evaluating the performance of your SVM regression model. However, there are subtle differences between the two metrics:**\n",
    "\n",
    "**MSE (Mean Squared Error):**\n",
    "\n",
    "- Measures the average of the squared differences between predicted and actual values.\n",
    "- It is sensitive to large errors, as it squares the errors.\n",
    "\n",
    "**RMSE (Root Mean Squared Error):**\n",
    "\n",
    "- Measures the square root of the average squared differences between predicted and actual values.\n",
    "- It is essentially the square root of MSE and provides a measure of the average magnitude of errors in the original units of the target variable.\n",
    "- Since you mentioned that both MSE and RMSE values are very close, the choice between them might depend on the specific context of your problem and your preferences. Here are some considerations:\n",
    "\n",
    "**Interpretability:**\n",
    "- RMSE is in the same units as the target variable, making it more interpretable in the context of your problem. If interpretability is crucial, RMSE might be a slightly better choice.\n",
    "\n",
    "- Sensitivity to Large Errors: If your dataset has outliers or large errors that you want to be more penalized, MSE might be more appropriate since it squares the errors.\n",
    "\n",
    "**In practice, both MSE and RMSE are commonly used interchangeably, and the choice between them often comes down to personal preference or the specific requirements of your analysis. If there is no strong reason to prefer one over the other in your context, you can choose either metric with confidence.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527857be-64ba-4af4-ae41-d9c57ee155c7",
   "metadata": {},
   "source": [
    "#### Q5. You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830cd74-84d6-4071-8a09-fca9449c34e9",
   "metadata": {},
   "source": [
    "**If your goal is to measure how well the model explains the variance in the target variable, the most appropriate evaluation metric is the R-squared (Coefficient of Determination). R-squared is particularly useful for regression models as it quantifies the proportion of the variance in the dependent variable (target) that is predictable from the independent variables (features).**\n",
    "\n",
    "- In scikit-learn, you can calculate R-squared using the r2_score function from the sklearn.metrics module. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de945c10-5b84-48ea-a465-5410149da208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: -1496.2100215601395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with your dataset, and the target variable is 'price'\n",
    "# For example, you might load your data like this:\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Assuming 'X' contains your features and 'y' contains your target variable\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Impute missing values in X\n",
    "imputer = SimpleImputer(strategy='mean')  # You can choose a different strategy\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize and train the LinearSVR model\n",
    "svm_model = LinearSVR()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df027fb9-e83f-41fa-8472-f5f6eebd6b0a",
   "metadata": {},
   "source": [
    "#### Q5. You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216d7f24-86ce-475f-8975-d2cd35868386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (Linear): 0.4683159942273376\n",
      "R-squared (Polynomial): 0.42782260299494645\n",
      "R-squared (RBF): 0.41474802067439187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Create and train your HistGradientBoostingRegressor models\n",
    "linear_model = HistGradientBoostingRegressor(loss='squared_error', max_iter=100)\n",
    "poly_model = HistGradientBoostingRegressor(loss='squared_error', max_iter=100)\n",
    "rbf_model = HistGradientBoostingRegressor(loss='squared_error', max_iter=100)\n",
    "\n",
    "# Fit the models\n",
    "linear_model.fit(X_train, y_train)\n",
    "poly_model.fit(X_train, y_train)\n",
    "rbf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "y_pred_poly = poly_model.predict(X_test)\n",
    "y_pred_rbf = rbf_model.predict(X_test)\n",
    "\n",
    "# Calculate R-squared for each model\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "r2_rbf = r2_score(y_test, y_pred_rbf)\n",
    "\n",
    "print(f'R-squared (Linear): {r2_linear}')\n",
    "print(f'R-squared (Polynomial): {r2_poly}')\n",
    "print(f'R-squared (RBF): {r2_rbf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a63bbe-a762-414c-a07e-911d9f8b6b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
